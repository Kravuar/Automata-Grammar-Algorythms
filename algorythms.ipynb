{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr1nmQhl6MPS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing state machine"
      ],
      "metadata": {
        "id": "O3IWGiZ1Mxtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SM:\n",
        "  def __init__(self, Σ, S, S0, Sf):\n",
        "    self.Σ = set(Σ)\n",
        "    self.S = set(S)\n",
        "    self.S0 = set(S0)\n",
        "    self.Sf = set(Sf)\n",
        "\n",
        "    if (not (self.S0 <= self.S and self.Sf <= self.S)):\n",
        "      raise ValueError(\"S0 and Sf should be subsets of S\")  \n",
        "    self.δ = pd.DataFrame(columns=np.unique(list(Σ)), index=np.unique(list(S))).applymap(lambda x: set() if pd.isna(x) else x)\n",
        "\n",
        "  def __repr__(self):\n",
        "        return repr(self.δ)\n",
        "\n",
        "  def init(self):\n",
        "    for state in self.S:\n",
        "      for signal in self.Σ:\n",
        "        while(True):\n",
        "          toStates = set(input(f'({state};{signal}) ==> ').split())\n",
        "\n",
        "          if (len(toStates) == 0):\n",
        "            break;\n",
        "          elif (any(toState not in self.S for toState in toStates)):\n",
        "            print(\"Found non existing state in user input.\")\n",
        "          else:\n",
        "            self.δ.loc[state, signal] = toStates\n",
        "            break\n",
        "\n",
        "  def checkPathFrom(self, path, state):\n",
        "    if len(path) == 0:\n",
        "      return state in self.Sf\n",
        "    \n",
        "    signal, *tail = path\n",
        "    reachable = self.δ.at[state, signal]\n",
        "    return any(result == True for result in [self.checkPathFrom(tail, next) for next in reachable])\n",
        "      \n",
        "\n",
        "  def checkPath(self, path):\n",
        "    return any(result == True for result in [self.checkPathFrom(path, beginning) for beginning in self.S0])"
      ],
      "metadata": {
        "id": "2Q8Y8Q0sNULd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User input"
      ],
      "metadata": {
        "id": "Cw0DohfZM2KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SM(Σ=['ε', 'a', 'b'], S=['q0', 'q1', 'qf'], S0=['q0'], Sf=['qf'])\n",
        "sm.init()\n",
        "sm"
      ],
      "metadata": {
        "id": "eakk_ls075du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df0cef3-9aa8-426d-f264-13b417216190"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(q1;b) ==> q1\n",
            "(q1;ε) ==> \n",
            "(q1;a) ==> q0 qf\n",
            "(qf;b) ==> \n",
            "(qf;ε) ==> q1\n",
            "(qf;a) ==> \n",
            "(q0;b) ==> qf\n",
            "(q0;ε) ==> q1\n",
            "(q0;a) ==> \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           a     b     ε\n",
              "q0        {}  {qf}  {q1}\n",
              "q1  {qf, q0}  {q1}    {}\n",
              "qf        {}    {}  {q1}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determination Subject\n",
        "sm = SM(Σ=['ε', 'a', 'b'], S=['q0', 'q1', 'qf'], S0=['q0'], Sf=['qf'])\n",
        "\n",
        "sm.δ.at['q0', 'ε'] = {'q1'}\n",
        "sm.δ.at['q0', 'b'] = {'qf'}\n",
        "sm.δ.at['q1', 'a'] = {'q0', 'qf'}\n",
        "sm.δ.at['q1', 'b'] = {'q1'}\n",
        "sm.δ.at['qf', 'ε'] = {'q1'}\n",
        "\n",
        "sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL14YeQ3ILja",
        "outputId": "55c81965-876f-44c8-b4f6-719f9aeb912f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           a     b     ε\n",
              "q0        {}  {qf}  {q1}\n",
              "q1  {qf, q0}  {q1}    {}\n",
              "qf        {}    {}  {q1}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimization Subject\n",
        "sm = SM(Σ=['a', 'b'], S=['q0', 'q1', 'q2', 'q3', 'q4', 'q5'], S0=['q0'], Sf=['q3', 'q4', 'q5'])\n",
        "\n",
        "sm.δ.at['q0', 'a'] = {'q1'}\n",
        "sm.δ.at['q0', 'b'] = {'q2'}\n",
        "sm.δ.at['q1', 'a'] = {'q2'}\n",
        "sm.δ.at['q1', 'b'] = {'q3'}\n",
        "sm.δ.at['q2', 'a'] = {'q1'}\n",
        "sm.δ.at['q2', 'b'] = {'q4'}\n",
        "sm.δ.at['q3', 'a'] = {'q5'}\n",
        "sm.δ.at['q3', 'b'] = {'q4'}\n",
        "sm.δ.at['q4', 'a'] = {'q3'}\n",
        "sm.δ.at['q4', 'b'] = {'q4'}\n",
        "sm.δ.at['q5', 'a'] = {'q5'}\n",
        "sm.δ.at['q5', 'b'] = {'q4'}\n",
        "\n",
        "sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc5ALwBm8Opc",
        "outputId": "542aa2ee-319b-43c0-e476-9734466fcdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       a     b\n",
              "q0  {q1}  {q2}\n",
              "q1  {q2}  {q3}\n",
              "q2  {q1}  {q4}\n",
              "q3  {q5}  {q4}\n",
              "q4  {q3}  {q4}\n",
              "q5  {q5}  {q4}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Epsilon transitions"
      ],
      "metadata": {
        "id": "gAR1_zEADpN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getReachable(sm, state, visited=set(), signal=None):\n",
        "  epsilonReachable = set()\n",
        "  epsilon = sm.δ.at[state, 'ε']\n",
        "  for next in [next for next in epsilon if next not in visited]:\n",
        "    epsilonReachable.add(next)\n",
        "    epsilonReachable.update(getReachable(sm, next, visited.union(epsilonReachable), signal))\n",
        "\n",
        "  reachable = set()\n",
        "  if signal != None:\n",
        "    nextReachable = sm.δ.at[state, signal]\n",
        "    for next in [next for next in nextReachable if next not in visited]:\n",
        "      reachable.add(next)\n",
        "      reachable.update(getReachable(sm, next, visited.union(reachable)))\n",
        "  else:\n",
        "    reachable.update(epsilonReachable)\n",
        "\n",
        "  return reachable\n",
        "\n",
        "\n",
        "def getEpsilonClosures(sm):\n",
        "  ec = {}\n",
        "  for state in sm.S:\n",
        "    queue = [state]\n",
        "    visited = {state}\n",
        "\n",
        "    reachable = {state}\n",
        "    while (len(queue) != 0):\n",
        "      fromState = queue.pop()\n",
        "      newReachable = sm.δ.at[fromState, 'ε']\n",
        "      toStates = [state for state in newReachable if state not in visited]\n",
        "\n",
        "      reachable.update(toStates)\n",
        "      queue = queue + toStates\n",
        "    \n",
        "    ec[state] = reachable\n",
        "  \n",
        "  return ec\n",
        "\n",
        "\n",
        "def removeEpsilonTransitions(sm):\n",
        "  epsilonClosures = getEpsilonClosures(sm)\n",
        "  reachableFromStartStates = {state for s0 in sm.S0 for state in epsilonClosures[s0]}\n",
        "\n",
        "  startClosures = {}\n",
        "  otherClosures = {}\n",
        "  finalClosures = {}\n",
        "  for state, closure in epsilonClosures.items():\n",
        "    lastClassified = None\n",
        "    if closure <= reachableFromStartStates:\n",
        "      key = f'S0{len(startClosures)}({state})'\n",
        "      startClosures[key] = (state, closure)\n",
        "      lastClassified = key\n",
        "    if any(reachable in sm.Sf for reachable in closure):\n",
        "      key = f'Sf{len(finalClosures)}({state})'\n",
        "      if lastClassified is not None:\n",
        "        key = lastClassified\n",
        "      finalClosures[key] = (state, closure)\n",
        "      lastClassified = key\n",
        "    if lastClassified is None:\n",
        "      otherClosures[f'S{len(otherClosures) + 1}({state})'] = (state, closure)\n",
        "  \n",
        "  startStates = set(startClosures.keys())\n",
        "  otherStates = set(otherClosures.keys())\n",
        "  finalStates = set(finalClosures.keys())\n",
        "  epsilonless_Σ = [signal for signal in sm.Σ if signal != 'ε']\n",
        "  cleanSM = SM(epsilonless_Σ, startStates.union(otherStates).union(finalStates), startStates, finalStates)\n",
        "\n",
        "  allClosures = {}\n",
        "  allClosures.update(startClosures)\n",
        "  allClosures.update(otherClosures)\n",
        "  allClosures.update(finalClosures)\n",
        "\n",
        "  for signal in epsilonless_Σ:\n",
        "    for state in cleanSM.S:\n",
        "      closure = allClosures[state][1]\n",
        "      reachable = set()\n",
        "      for oldState in closure:\n",
        "        reachable.update(getReachable(sm, oldState, signal=signal))\n",
        "      newStates = {newState for newState, (_, closure) in allClosures.items() if closure <= reachable}\n",
        "      cleanSM.δ.at[state, signal] = newStates\n",
        "\n",
        "  return cleanSM, epsilonClosures"
      ],
      "metadata": {
        "id": "PcPdvOglMwyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determinization"
      ],
      "metadata": {
        "id": "xduuct3BDsZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def determine(sm):\n",
        "  if 'ε' in sm.Σ:\n",
        "    sm, _ = removeEpsilonTransitions(sm)\n",
        "\n",
        "  mappings = {'P0': set(sm.S0)}\n",
        "  nonDetermined = ['P0']\n",
        "\n",
        "  determined = SM(sm.Σ, nonDetermined, nonDetermined, [])\n",
        "  while (len(nonDetermined) != 0):\n",
        "    toDetermine = nonDetermined.pop()\n",
        "    for signal in determined.Σ:\n",
        "      reachable = set()\n",
        "      for state in mappings[toDetermine]:\n",
        "        reachable.update(sm.δ.at[state,signal])\n",
        "\n",
        "      if len(reachable) != 0:\n",
        "        mapping = None\n",
        "        for key, value in mappings.items():\n",
        "          if reachable == value:\n",
        "            mapping = key\n",
        "            break\n",
        "        \n",
        "        if not mapping:\n",
        "          key = f'P{len(mappings)}'\n",
        "          mappings[key] = reachable\n",
        "          mapping = key\n",
        "          nonDetermined.append(mapping)\n",
        "          row = pd.DataFrame(columns=determined.δ.columns, index=[mapping])\n",
        "          determined.δ = pd.concat([determined.δ, row])\n",
        "\n",
        "        destination = {mapping}\n",
        "      else:\n",
        "        destination = {}\n",
        "\n",
        "      determined.δ.at[toDetermine, signal] = destination\n",
        "\n",
        "  determined.S = set(mappings.keys())\n",
        "  determined.Sf = {state for state, mapping in mappings.items() if any(oldState in sm.Sf for oldState in mapping)}\n",
        "  return determined, mappings"
      ],
      "metadata": {
        "id": "8ZjLqB32gsYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimization"
      ],
      "metadata": {
        "id": "8d1k9zvlDuPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def isDetermined(sm):\n",
        "  return all(len(way) <= 1 for way in sm.δ.to_numpy().flatten())\n",
        "\n",
        "\n",
        "def getAllReachable(sm):\n",
        "  reachable = set(sm.S0)\n",
        "  newStates = set(sm.S0)\n",
        "\n",
        "  while (newStates != set()):\n",
        "    temp = set()\n",
        "    for state in newStates:\n",
        "        for signal in sm.Σ:\n",
        "            temp.update(sm.δ.loc[state, signal])\n",
        "    newStates = temp - reachable\n",
        "    reachable.update(newStates)\n",
        "    \n",
        "  return reachable\n",
        "\n",
        "\n",
        "def removeUnreachable(sm):\n",
        "  reachable = getAllReachable(sm)\n",
        "  cleanSM = SM(sm.Σ, reachable, sm.S0.intersection(reachable), sm.Sf.intersection(reachable))\n",
        "\n",
        "  for signal in sm.Σ:\n",
        "    for state in reachable:\n",
        "      cleanSM.δ.loc[state, signal] = {state for state in sm.δ.loc[state, signal] if state in reachable}\n",
        "    \n",
        "  return cleanSM\n",
        "\n",
        "\n",
        "def minimize(sm):\n",
        "  if not isDetermined:\n",
        "    sm = determine(sm)\n",
        "  sm = removeUnreachable(sm)\n",
        "\n",
        "  classes = getClasses(sm)\n",
        "  states = set(classes.keys())\n",
        "  min = SM(sm.Σ, states, {'M0'}, {state for state in states if state.startswith('Mf')})\n",
        "  \n",
        "  for fromClass in min.S:\n",
        "    for signal in min.Σ:\n",
        "      if min.δ.loc[fromClass, signal] != set():\n",
        "        continue\n",
        "      for toClass, states in classes.items():\n",
        "        found = False\n",
        "        for state in classes[fromClass]:\n",
        "          if len(sm.δ.loc[state, signal]) == 0:\n",
        "            continue\n",
        "          oldDestination = next(iter(sm.δ.loc[state, signal]))\n",
        "          if oldDestination in states:\n",
        "            min.δ.loc[fromClass, signal] = toClass\n",
        "            found = True\n",
        "            break\n",
        "        if found:\n",
        "          break\n",
        "  \n",
        "  return min, classes\n",
        "\n",
        "\n",
        "def organize(classes, sm):\n",
        "  organized = {}\n",
        "  i = 1\n",
        "  f = 0\n",
        "  for clazz in classes:\n",
        "    if any(state in sm.S0 for state in clazz):\n",
        "      key = f'M0'\n",
        "    elif any(state in sm.Sf for state in clazz):\n",
        "      key = f'Mf{f}'\n",
        "      f = f + 1\n",
        "    else:\n",
        "      key = f'M{i}'\n",
        "      i = i + 1\n",
        "    organized[key] = clazz\n",
        "  return organized\n",
        "\n",
        "\n",
        "def getClasses(sm):\n",
        "  prevXi = [sm.Sf, sm.S - sm.Sf]\n",
        "  while True:  \n",
        "    newXi = []\n",
        "    for currentClass in prevXi:\n",
        "      classDf = sm.δ.loc[list(currentClass)]\n",
        "      if len(currentClass) != 1:\n",
        "        for signal in sm.Σ:\n",
        "          classSignalDf = classDf[signal]\n",
        "          \n",
        "          subClasses = []\n",
        "          for state in classDf.index.values:\n",
        "            if len(classSignalDf[state]) == 0:\n",
        "              subClasses.append(prevXi.index(currentClass))\n",
        "              continue\n",
        "            for i, clazz in enumerate(prevXi):\n",
        "              if next(iter(classSignalDf[state])) in clazz:\n",
        "                subClasses.append(i)\n",
        "                break\n",
        "          if len(set(subClasses)) == 1:\n",
        "            continue\n",
        "          \n",
        "          subClasses = map(lambda x: x.to_numpy(), list(classSignalDf.index.groupby(subClasses).values()))\n",
        "          classDf = classDf.loc[next(subClasses)]\n",
        "          for clazz in subClasses:\n",
        "            newXi.append(set(clazz))\n",
        "      newXi.append(set(classDf.index.values))\n",
        "\n",
        "    if newXi == prevXi:\n",
        "      return organize(newXi, sm)\n",
        "    prevXi = newXi"
      ],
      "metadata": {
        "id": "3z67pL0JDxlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Epsilon transitions removal"
      ],
      "metadata": {
        "id": "xVgkrQq-M4LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleanSM, closures = removeEpsilonTransitions(sm)\n",
        "print(cleanSM)\n",
        "print('\\nClosures:', closures)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97ca5e9-1f25-44c7-ac6c-05217dcfa75f",
        "id": "DFLbxKJGnSGn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   a                   b\n",
            "S00(q1)  {S01(q0), S00(q1), Sf0(qf)}           {S00(q1)}\n",
            "S01(q0)  {S01(q0), S00(q1), Sf0(qf)}  {S00(q1), Sf0(qf)}\n",
            "Sf0(qf)  {S01(q0), S00(q1), Sf0(qf)}           {S00(q1)}\n",
            "\n",
            "Closures: {'q1': {'q1'}, 'qf': {'q1', 'qf'}, 'q0': {'q1', 'q0'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'S: {cleanSM.S}', f'S0: {cleanSM.S0}', f'Sf: {cleanSM.Sf}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9d43e2-780d-481b-911d-98903f4d6881",
        "id": "zg_hE_jJnS02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S: {'S01(q0)', 'S00(q1)', 'Sf0(qf)'} S0: {'S01(q0)', 'S00(q1)'} Sf: {'Sf0(qf)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determinization"
      ],
      "metadata": {
        "id": "-SmNWmt3xBXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "determined, mappings = determine(cleanSM)\n",
        "print(determined)\n",
        "print('\\nMappings:', mappings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sev06knfpKF1",
        "outputId": "907f086a-7efd-43b0-abfe-a96333794fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       a     b\n",
            "P0  {P2}  {P1}\n",
            "P2  {P2}  {P1}\n",
            "P1  {P2}  {P3}\n",
            "P3  {P2}  {P3}\n",
            "\n",
            "Mappings: {'P0': {'S01(q0)', 'S00(q1)'}, 'P1': {'S00(q1)', 'Sf0(qf)'}, 'P2': {'S01(q0)', 'Sf0(qf)', 'S00(q1)'}, 'P3': {'S00(q1)'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'S: {determined.S}', f'S0: {determined.S0}', f'Sf: {determined.Sf}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdBhC_NZ_JPT",
        "outputId": "5846c064-0e84-46a7-c330-8723cbb0bfdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S: {'P3', 'P1', 'P2', 'P0'} S0: {'P0'} Sf: {'P1', 'P2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check path"
      ],
      "metadata": {
        "id": "abP169gpxDOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Should be True: {determined.checkPath(['a', 'b', 'b', 'b', 'b', 'b', 'a'])}\")\n",
        "print(f\"Should be False: {determined.checkPath(['a','b','b'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-jK780exRb2",
        "outputId": "712e9f3a-6cdd-4f37-f230-bc558fd3071a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Should be True: True\n",
            "Should be False: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimization"
      ],
      "metadata": {
        "id": "AtymBWHmD1cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minimized, classes = minimize(sm)\n",
        "print(minimized)\n",
        "print('\\nClasses:', classes)"
      ],
      "metadata": {
        "id": "2gwuILy_TRTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d4d0b3-dc05-4282-fd5e-e81753d33864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       a    b\n",
            "M0    M1   M1\n",
            "M1    M1  Mf0\n",
            "Mf0  Mf0  Mf0\n",
            "\n",
            "Classes: {'Mf0': {'q4', 'q5', 'q3'}, 'M0': {'q0'}, 'M1': {'q2', 'q1'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'S: {minimized.S}', f'S0: {minimized.S0}', f'Sf: {minimized.Sf}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmgREM9T9yeI",
        "outputId": "abb9ba7c-cf42-4ed6-a17b-e232c0dbff39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S: {'M1', 'M0', 'Mf0'} S0: {'M0'} Sf: {'Mf0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Grammar\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UOUDtNKxzxa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Set, Tuple, List, Iterable"
      ],
      "metadata": {
        "id": "srTf3lZhz25B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trimDuplicate(left: Iterable, right: Iterable, until: int = None):\n",
        "  l1, l2 = len(left), len(right)\n",
        "  if until:\n",
        "    default = min(until, l1, l2)\n",
        "    zipped = zip(left[:until], right[:until])\n",
        "  else:\n",
        "    default = min(l1, l2)\n",
        "    zipped = zip(left, right)\n",
        "  idx = next(iter([i for i, (l, r) in enumerate(zipped) if l != r]), default)\n",
        "  return left[idx:], right[idx:]\n",
        "\n",
        "class Grammar:\n",
        "  def __init__(self, T: Set[str], N: Set[str], P: List[Tuple[str, str]], S: str):\n",
        "    self.T = T.copy()\n",
        "    self.N = N.copy()\n",
        "    if not all(token in self.N for token in self.tokenize_string(S)):\n",
        "      raise ValueError(\"S should be in N.\")\n",
        "    self.P = P.copy()\n",
        "    self.S = S\n",
        "  \n",
        "  def tokenize_string(self, s: str) -> List[str]:\n",
        "    if s == '':\n",
        "      return []\n",
        "    tokens = []\n",
        "    sub = s\n",
        "    while sub:\n",
        "      found_match = False\n",
        "      for token in sorted(self.T.union(self.N), key=len, reverse=True):\n",
        "        if sub.startswith(token):\n",
        "          tokens.append(token)\n",
        "          sub = sub[len(token):]\n",
        "          found_match = True\n",
        "          break\n",
        "      if not found_match:\n",
        "        raise ValueError(f\"Cannot tokenize string: '{s}'. Error in the substring: '{sub}'\")\n",
        "    return tokens\n",
        "  \n",
        "  def tokenize(self, p: Tuple[str, str]) -> Tuple[List[str], List[str]]:\n",
        "    if p not in self.P:\n",
        "        raise ValueError(f\"Unresolved production: {p}\")\n",
        "    (left, right) = p\n",
        "    return (self.tokenize_string(left), self.tokenize_string(right))\n",
        "\n",
        "  # Type 3 R: A → Bγ | γ, where γ ∈ T*; A, B ∈ N.\n",
        "  #           A → γB | γ, where γ ∈ T*; A, B ∈ N.\n",
        "  # (S → ε is possible, but S shouldn't be in any rhs).\n",
        "  def _chomsky_t3(self, tokenized) -> bool:\n",
        "    rhsContainsS = any(self.S in rhs for _, rhs in tokenized)\n",
        "    for lhs, rhs in tokenized:\n",
        "      if len(lhs) != 1 or len(rhs) > 2:\n",
        "        return False\n",
        "      if lhs[0] not in self.N:\n",
        "        return False\n",
        "      if rhs == []:\n",
        "        if lhs[0] == self.S and rhsContainsS: # S → ε\n",
        "          return False\n",
        "        continue\n",
        "      bad = not(rhs[0] in self.N and rhs[-1] in self.T) # A → Bγ\n",
        "      if bad:\n",
        "        bad = not(rhs[-1] in self.N and rhs[0] in self.T) # # A → γB\n",
        "      if bad:\n",
        "        bad = rhs[0] not in self.T # A → γ\n",
        "      if bad:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  # Type 2 CF: A → β, where A ∈ N, β ∈ {T ∪ N}+.\n",
        "  def _chomsky_t2(self, tokenized) -> bool:\n",
        "    for lhs, rhs in tokenized:\n",
        "      if lhs == []:\n",
        "        return False\n",
        "      if not(len(lhs) == 1 and lhs[0] in self.N and rhs != []):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  # Type 1_1 CS: αAβ → αγβ, where α, β ∈ {T ∪ N}∗; A ∈ N; γ ∈ {T ∪ N}+ (S → ε is possible, but S shouldn't be in any rhs).\n",
        "  def _chomsky_t1_1(self, tokenized) -> bool:\n",
        "    rhsContainsS = any(self.S in rhs for _, rhs in tokenized)\n",
        "    for lhs, rhs in tokenized:\n",
        "      if len(lhs) == len(rhs) == 1:\n",
        "        if lhs[0] == self.S and rhs == [] and rhsContainsS:\n",
        "          return False  \n",
        "      lastN = next(iter([i for i, token in enumerate(lhs) if token in self.N]), None)\n",
        "      if lastN == None:\n",
        "        return False\n",
        "      lhs_t, rhs_t = trimDuplicate(lhs, rhs, lastN)\n",
        "      lhs_t, rhs_t = trimDuplicate(lhs_t[::-1], rhs_t[::-1])\n",
        "      A, γ = lhs_t[::-1], rhs_t[::-1]\n",
        "\n",
        "      if len(A) != 1 or len(γ) == 0:\n",
        "        return False\n",
        "    return True  \n",
        "\n",
        "  # Type 1_2 NT: α → β, where α, β ∈ {T ∪ N}+; |α|⩽|β| (S → ε is possible, but S shouldn't be in any rhs).\n",
        "  def _chomsky_t1_2(self, tokenized) -> bool:\n",
        "    rhsContainsS = any(self.S in rhs for _, rhs in tokenized)\n",
        "    for lhs, rhs in tokenized:\n",
        "      if lhs == []:\n",
        "        return False\n",
        "      if lhs[0] == self.S and rhs == [] and rhsContainsS: # S → ε\n",
        "        return False \n",
        "      if len(lhs) > len(rhs): # |α|⩽|β|\n",
        "        return False  \n",
        "    return True\n",
        "\n",
        "  # Type 0 U: α → β, where α ∈ {T U N}+, containing at least 1 x ∈ N; β ∈ {T ∪ N}∗.\n",
        "  def _chomsky_t0(self, tokenized) -> bool:\n",
        "    for lhs, _ in tokenized:\n",
        "      if not any(token in self.N for token in lhs):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  def chomsky(self) -> str:\n",
        "    tokenized = [self.tokenize(p) for p in self.P]\n",
        "\n",
        "    if self._chomsky_t3(tokenized):\n",
        "      return \"Type 3 (regular) grammar\"\n",
        "    if self._chomsky_t2(tokenized):\n",
        "      return \"Type 2 (context-free) grammar\"\n",
        "    if self._chomsky_t1_1(tokenized):\n",
        "      return \"Type 1 (сontext-sensitive) grammar\"\n",
        "    if self._chomsky_t1_2(tokenized):\n",
        "      return \"Type 1 (non-trimming) grammar\"\n",
        "    if self._chomsky_t0(tokenized):\n",
        "      return \"Type 0 (unrestricted) grammar\"\n",
        "    \n",
        "    return \"Grammar of undefined type\"\n",
        "\n",
        "  def toSM(self):\n",
        "    tokenized = [self.tokenize(p) for p in self.P]\n",
        "    if not self._chomsky_t3(tokenized):\n",
        "      raise ValueError(f\"Cannot convert non-regular grammar.\")\n",
        "\n",
        "    dump_state = 'N`'\n",
        "    sm = SM(self.T.union(['ε']), self.N.union([self.S, dump_state]), set([self.S]), set([dump_state]))\n",
        "    \n",
        "    # A → γB, where γ ∈ T*; A, B ∈ N. ===> a transition from state A to state B labelled γ\n",
        "    # A → γ, where γ ∈ T; A ∈ N. ===> a transition from state A to state Dump labelled γ\n",
        "    for lhs, rhs in tokenized:\n",
        "      if rhs == []:\n",
        "        sm.δ.at[lhs[0], 'ε'] = {dump_state}\n",
        "      elif rhs[-1] in self.N:\n",
        "        signal = rhs[0] if len(rhs) == 2 else 'ε'\n",
        "        sm.δ.at[lhs[0], signal].add(rhs[-1]) \n",
        "      elif rhs[0] in self.T:\n",
        "        # If exists lhs -> rhs[0] N => add N to F\n",
        "        hasCover = False\n",
        "        for lhs_c, rhs_c in tokenized:\n",
        "          if lhs == lhs_c and len(rhs_c) == 2 and rhs_c[0] == rhs[0] and rhs_c[-1] in self.N:\n",
        "            sm.Sf.add(rhs_c[-1])\n",
        "            hasCover = True\n",
        "        if not hasCover:\n",
        "          sm.δ.at[lhs[0], rhs[0]].add(dump_state) \n",
        "    return sm\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "       return f'Grammar <T: {self.T}, N: {self.N}, P: {self.P}, S: {self.S}>'"
      ],
      "metadata": {
        "id": "G9lzy_kjz6y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Tests"
      ],
      "metadata": {
        "id": "E7DK8fL6ukbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type 3"
      ],
      "metadata": {
        "id": "GB1IdSsDuokZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g3_1 = Grammar(T={'a', 'b'}, N={'S'}, P=[('S', 'aS'), ('S', 'b')], S='S')\n",
        "g3_2 = Grammar({\"0\", \"1\"}, {\"S\"}, [(\"S\", \"01\"), (\"S\", \"10\"), (\"S\", \"\")], \"S\")\n",
        "print(g3_1.chomsky())\n",
        "print(g3_2.chomsky())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrUK7i01ui8n",
        "outputId": "b73755c3-afae-46ea-9200-ff419f79f13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 3 (regular) grammar\n",
            "Type 3 (regular) grammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type 2"
      ],
      "metadata": {
        "id": "Nat-DnhhvOHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g2_1 = Grammar({\"a\", \"b\", \"c\"}, {\"S\", \"A\", \"B\", \"C\"}, [(\"S\", \"ABC\"), (\"A\", \"aA\"), (\"B\", \"bC\"), (\"C\", \"c\")], \"S\")\n",
        "g2_2 = Grammar({\"a\", \"b\"}, {\"S\", \"A\", \"B\"}, [(\"S\", \"AB\"), (\"A\", \"aA\"), (\"B\", \"b\")], \"S\")\n",
        "print(g2_1.chomsky())\n",
        "print(g2_2.chomsky())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vZjzNfkvPlk",
        "outputId": "e3458e9b-0a7a-4580-b2aa-eeda7f8a70f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 2 (context-free) grammar\n",
            "Type 2 (context-free) grammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type 1 non-trimming"
      ],
      "metadata": {
        "id": "Yk6jpQtQvVhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g1_11 = Grammar(T={\"a\", \"b\"}, N={\"S\", \"A\", \"B\"}, P=[(\"SA\", \"aSB\"), (\"SB\", \"BB\"), (\"aB\", \"ab\"), (\"bB\", \"bb\")], S=\"SA\")\n",
        "g1_12 = Grammar({\"a\", \"b\"}, {\"S\", \"A\", \"B\"}, [(\"S\", \"AB\"), (\"A\", \"aA\"), (\"Bb\", \"bb\")], \"S\")\n",
        "print(g1_11.chomsky())\n",
        "print(g1_12.chomsky())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nrj8JJGvYsw",
        "outputId": "d1093f4d-7297-4775-ac43-37c61bb84aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 1 (non-trimming) grammar\n",
            "Type 1 (non-trimming) grammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type 1 context-sensitive"
      ],
      "metadata": {
        "id": "aPdoXzU5rJde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g1_21 = Grammar({\"a\", \"b\", \"c\"}, {\"S\", \"T\"}, [(\"S\", \"aTb\"), (\"S\", \"ab\"), (\"aT\", \"aaTb\"), (\"aT\", \"ac\")], \"S\")\n",
        "g1_22 = Grammar({\"a\", \"b\", \"c\"}, {\"S\", \"A\", \"B\"}, [(\"S\", \"abc\"), (\"S\", \"A\"), (\"A\", \"aABc\"), (\"A\", \"abc\"), (\"cB\", \"cBc\"), (\"bB\", \"bb\")], \"S\")\n",
        "print(g1_21.chomsky())\n",
        "print(g1_22.chomsky())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e49943-9073-484f-8f0c-53ed0c8fc469",
        "id": "jTOMyUHdrJdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 1 (сontext-sensitive) grammar\n",
            "Type 1 (сontext-sensitive) grammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type 0"
      ],
      "metadata": {
        "id": "imj9k5w4vXpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g0_1 = Grammar(T={'a', 'b'}, N={'S'}, P=[('S', 'aSb'), ('S', '')], S='S')\n",
        "g0_2 = Grammar(T={'0', '1'}, N={'S', 'A'}, P=[('S', 'A0A1'), ('A', '0A1'), ('A', '')], S='S')\n",
        "print(g0_1.chomsky())\n",
        "print(g0_2.chomsky())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3wn4xrd_xYl",
        "outputId": "c6916ceb-17f7-43fb-a398-41b6b5e82abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 0 (unrestricted) grammar\n",
            "Type 0 (unrestricted) grammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type undefined"
      ],
      "metadata": {
        "id": "P_tX-4I6BeqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gu = Grammar(T={'0', '1'}, N={'S', 'A', 'B'}, P=[('S', 'AB'), ('A', '0A1'), ('B', '0B1'), ('', '0')], S='S')\n",
        "print(gu.chomsky())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQWhc8JZBdFB",
        "outputId": "b4ede30e-e39d-4571-fc88-90964b654cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar of undefined type\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification subject"
      ],
      "metadata": {
        "id": "07r4r1jWU1oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gg = Grammar(T={'+', '-', 'a', 'b'}, N={'S', 'x'}, P=[('S', 'x+x-x'), ('x', 'ax'), ('x', 'bx')], S='S')\n",
        "print(gg.chomsky())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyT6QQSsUduH",
        "outputId": "0635ccb7-0f6b-4fb3-9888-b866c4fe8db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 2 (context-free) grammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building an DFA from Grammar"
      ],
      "metadata": {
        "id": "sstOFDLO0Ue2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = Grammar(T={'0', '1', 'a', 'b', 'c'}, N={'E', 'A', 'B', 'C', 'D'}, P=[\n",
        "    ('E', '0A'), ('E', ''),\n",
        "    ('A', 'aB'), ('A', 'aD'), \n",
        "    ('B', 'bB'), ('B', '1C'), ('B', 'c'),\n",
        "    ('D', 'aD'), ('D', '0C'), ('D', 'c'),\n",
        "    ('C', '0C'), ('C', '1C'), ('C', 'c')\n",
        "], S='E')\n",
        "print(g.chomsky())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm09zeFL0U78",
        "outputId": "765514d1-bc2b-4c59-a169-d2e6ccb0c062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 3 (regular) grammar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm = g.toSM()\n",
        "sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b35d55-f5cf-4178-a286-13d387ccd365",
        "id": "NTxMGuEs1ajE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0    1       a    b     c     ε\n",
              "A    {}   {}  {B, D}   {}    {}    {}\n",
              "B    {}  {C}      {}  {B}  {N`}    {}\n",
              "C   {C}  {C}      {}   {}  {N`}    {}\n",
              "D   {C}   {}     {D}   {}  {N`}    {}\n",
              "E   {A}   {}      {}   {}    {}  {N`}\n",
              "N`   {}   {}      {}   {}    {}    {}"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'S: {sm.S}', f'S0: {sm.S0}', f'Sf: {sm.Sf}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEsxIE22rEOM",
        "outputId": "59324560-c6de-40d2-9f01-c1dcb1ca8f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S: {'B', 'E', 'N`', 'A', 'D', 'C'} S0: {'E'} Sf: {'N`'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determinization of converted FA"
      ],
      "metadata": {
        "id": "aypaQsiKQqfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "determined, mappings = determine(sm)\n",
        "print(determined)\n",
        "print('\\nMappings:', mappings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b61e52-2505-4cdd-fc9d-3b783db0a586",
        "id": "BTwXhuY2Q2YT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       0     1     a     b     c\n",
            "P0  {P1}    {}    {}    {}    {}\n",
            "P1    {}    {}  {P2}    {}    {}\n",
            "P2  {P4}  {P4}  {P5}  {P3}  {P6}\n",
            "P3    {}  {P4}    {}  {P3}  {P6}\n",
            "P4  {P4}  {P4}    {}    {}  {P6}\n",
            "P5  {P4}    {}  {P5}    {}  {P6}\n",
            "P6    {}    {}    {}    {}    {}\n",
            "\n",
            "Mappings: {'P0': {'S00(E)', 'S01(N`)'}, 'P1': {'S2(A)'}, 'P2': {'S1(B)', 'S3(D)'}, 'P3': {'S1(B)'}, 'P4': {'S4(C)'}, 'P5': {'S3(D)'}, 'P6': {'S01(N`)'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'S: {determined.S}', f'S0: {determined.S0}', f'Sf: {determined.Sf}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bcf590-36e5-47f1-d1cc-580bf235b027",
        "id": "2WNHywjCQ2YT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S: {'P4', 'P2', 'P0', 'P1', 'P5', 'P6', 'P3'} S0: {'P0'} Sf: {'P6', 'P0'}\n"
          ]
        }
      ]
    }
  ]
}